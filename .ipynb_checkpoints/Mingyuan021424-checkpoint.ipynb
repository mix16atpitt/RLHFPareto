{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a6853c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:11:02.603539Z",
     "start_time": "2024-02-15T12:10:55.199042Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np, numpy.random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b49062e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:11:02.637694Z",
     "start_time": "2024-02-15T12:11:02.606506Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(random_seed):\n",
    "#     random.seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.benckmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "    \n",
    "set_seed(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb598935",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:11:03.175622Z",
     "start_time": "2024-02-15T12:11:02.637694Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n",
      "CUDA version: 11.8\n",
      "ID of current CUDA device: 0\n",
      "Name of current CUDA device: Quadro M1000M\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA\n",
    " \n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    " \n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
    "       \n",
    "print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a75db29c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:11:03.218004Z",
     "start_time": "2024-02-15T12:11:03.177153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter-bott</th>\n",
       "      <th>parameter-cbbotr</th>\n",
       "      <th>parameter-cbheight</th>\n",
       "      <th>parameter-cbotr</th>\n",
       "      <th>parameter-cbtopr</th>\n",
       "      <th>parameter-cheight</th>\n",
       "      <th>parameter-ctopr</th>\n",
       "      <th>parameter-pitch</th>\n",
       "      <th>parameter-silvert</th>\n",
       "      <th>parameter-topt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95.718148</td>\n",
       "      <td>43.354505</td>\n",
       "      <td>216.598869</td>\n",
       "      <td>60.874317</td>\n",
       "      <td>131.467336</td>\n",
       "      <td>167.252109</td>\n",
       "      <td>34.541709</td>\n",
       "      <td>327.772442</td>\n",
       "      <td>5.402554</td>\n",
       "      <td>78.748219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.192794</td>\n",
       "      <td>68.338471</td>\n",
       "      <td>146.439212</td>\n",
       "      <td>123.218142</td>\n",
       "      <td>92.990379</td>\n",
       "      <td>660.143754</td>\n",
       "      <td>110.076490</td>\n",
       "      <td>384.452082</td>\n",
       "      <td>13.987269</td>\n",
       "      <td>43.500956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.759242</td>\n",
       "      <td>66.320557</td>\n",
       "      <td>946.568699</td>\n",
       "      <td>165.201964</td>\n",
       "      <td>79.994531</td>\n",
       "      <td>490.872671</td>\n",
       "      <td>78.274344</td>\n",
       "      <td>338.646017</td>\n",
       "      <td>3.293220</td>\n",
       "      <td>71.431971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.378067</td>\n",
       "      <td>7.885207</td>\n",
       "      <td>79.406897</td>\n",
       "      <td>91.347128</td>\n",
       "      <td>108.114417</td>\n",
       "      <td>282.759484</td>\n",
       "      <td>31.222274</td>\n",
       "      <td>343.268350</td>\n",
       "      <td>15.507130</td>\n",
       "      <td>77.861851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.933965</td>\n",
       "      <td>13.041809</td>\n",
       "      <td>608.350193</td>\n",
       "      <td>165.886507</td>\n",
       "      <td>168.164578</td>\n",
       "      <td>12.599300</td>\n",
       "      <td>49.941049</td>\n",
       "      <td>362.320432</td>\n",
       "      <td>14.774567</td>\n",
       "      <td>71.680716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parameter-bott  parameter-cbbotr  parameter-cbheight  parameter-cbotr  \\\n",
       "0       95.718148         43.354505          216.598869        60.874317   \n",
       "1       57.192794         68.338471          146.439212       123.218142   \n",
       "2       48.759242         66.320557          946.568699       165.201964   \n",
       "3       76.378067          7.885207           79.406897        91.347128   \n",
       "4       42.933965         13.041809          608.350193       165.886507   \n",
       "\n",
       "   parameter-cbtopr  parameter-cheight  parameter-ctopr  parameter-pitch  \\\n",
       "0        131.467336         167.252109        34.541709       327.772442   \n",
       "1         92.990379         660.143754       110.076490       384.452082   \n",
       "2         79.994531         490.872671        78.274344       338.646017   \n",
       "3        108.114417         282.759484        31.222274       343.268350   \n",
       "4        168.164578          12.599300        49.941049       362.320432   \n",
       "\n",
       "   parameter-silvert  parameter-topt  \n",
       "0           5.402554       78.748219  \n",
       "1          13.987269       43.500956  \n",
       "2           3.293220       71.431971  \n",
       "3          15.507130       77.861851  \n",
       "4          14.774567       71.680716  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvFile = pd.read_csv('Dataset/structure4.csv')\n",
    "df_parameter = csvFile.iloc[:, :10]\n",
    "\n",
    "df_SE = csvFile.iloc[:, 10:11]\n",
    "df_Tvis = csvFile.iloc[:, 12:13] * 100\n",
    "df_metric = pd.concat([df_Tvis, df_SE], axis=1)\n",
    "\n",
    "df_parameter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2524c7b7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T12:10:55.199Z"
    }
   },
   "outputs": [],
   "source": [
    "max_values_parameter = df_parameter.max()\n",
    "max_values_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e329f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T12:10:55.201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalization Parameters\n",
    "df_parameter_norm = df_parameter\n",
    "for i in range(len(df_parameter.columns)):\n",
    "    df_parameter_norm.iloc[:, i] = df_parameter.iloc[:, i] / max_values_parameter[i]\n",
    "    \n",
    "df_parameter_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6673ecdf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T12:10:55.202Z"
    }
   },
   "outputs": [],
   "source": [
    "max_values_metric = df_metric.max()\n",
    "max_values_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbdc1db",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T12:10:55.203Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Normalization Metrics (Tested: No Difference)\n",
    "\n",
    "# SE_min = 0\n",
    "# SE_max = 120\n",
    "# Tvis_min = 10\n",
    "# Tvis_max = 100\n",
    "\n",
    "# df_SE_norm = (df_SE - SE_min) / (SE_max - SE_min)\n",
    "# df_Tvis_norm = (df_Tvis - Tvis_min) / (Tvis_max - Tvis_min)\n",
    "# df_metric_norm = pd.concat([df_Tvis_norm, df_SE_norm], axis=1)\n",
    "\n",
    "# plt.scatter(df_Tvis_norm, df_SE_norm, s=0.1)\n",
    "# plt.xlabel(\"Tvis(%)_norm\")\n",
    "# plt.ylabel(\"SE_norm\")\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d0d7c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T12:10:55.204Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_Tvis, df_SE, s=0.1)\n",
    "plt.xlabel(\"Tvis(%)\")\n",
    "plt.ylabel(\"SE\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93b3392",
   "metadata": {},
   "source": [
    "Dataset for Reward Model, $\\forall x$: function $r_\\theta : \\mathcal{Y} \\mapsto z$\n",
    "\n",
    "$x$: 2d vector sum to 1\n",
    "\n",
    "$y_i, y_j$: indicate by index\n",
    "\n",
    "$z_{y_i, y_j | x}$: preference output\n",
    "\n",
    "Data for Pretrained Base Pareto Model: function $f_\\theta : \\mathcal{X} \\mapsto \\mathcal{Y}$\n",
    "\n",
    "this can be trained naively: choose the best completion $y_i$ under the most weighted metric(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb8796",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T12:10:55.206Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Dataset for Reward Model and Pretrained Base Pareto Model\n",
    "parameter_mat = df_parameter.to_numpy()\n",
    "metric_mat = df_metric.to_numpy()\n",
    "\n",
    "dim_x = 2\n",
    "dim_y = len(df_parameter_norm.columns)\n",
    "x_n = 100\n",
    "y_n = len(df_parameter_norm)\n",
    "\n",
    "Xset = []\n",
    "Yset = []\n",
    "Zset = []\n",
    "Mset = []\n",
    "Rset = []\n",
    "\n",
    "for i in tqdm(range(x_n)):\n",
    "    x = np.array(([i/x_n, 1-i/x_n]))\n",
    "    Xset.append(x.flatten())\n",
    "    value_x = np.dot(metric_mat, x.T)\n",
    "\n",
    "    index_sorted = sorted(range(len(value_x)), key=lambda k: value_x[k])\n",
    "    Yset.append(parameter_mat[index_sorted[-1]])\n",
    "    Mset.append(metric_mat[index_sorted[-1]])\n",
    "\n",
    "    \n",
    "    # Reward Dataset Design\n",
    "    Rset.append(np.array([value_x]).T)\n",
    "        \n",
    "#     z_mat = [[0 for i in range(y_n)] for j in range(y_n)]\n",
    "    \n",
    "#     for j in range(y_n):\n",
    "#         z_mat[index_sorted[j]][index_sorted[j]] = np.random.binomial(1, 0.5, 1)\n",
    "#         for k in range(1, y_n - j):\n",
    "#             z_mat[index_sorted[j]][index_sorted[k]] = 1\n",
    "#             z_mat[index_sorted[k]][index_sorted[j]] = 0\n",
    "            \n",
    "#     Zset.append(z_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a723e97",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T12:10:55.208Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pareto from Data for Pretrain base model\n",
    "\n",
    "plt.scatter([Mset[i][0] for i in range(x_n)], [Mset[i][1] for i in range(x_n)], s=0.1)\n",
    "plt.xlabel(\"Tvis(%)\")\n",
    "plt.ylabel(\"SE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1331ab3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T12:10:55.209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pretrain base model of Pareto\n",
    "class TwoToTenNet(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_size=64):\n",
    "        super(TwoToTenNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, action_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        state = torch.relu(self.fc1(state))  # ReLU activation for the first layer\n",
    "        state = self.fc2(state)  # Output layer without activation function\n",
    "        return state\n",
    "\n",
    "Xset_tensor = torch.from_numpy(np.array(Xset)).to(torch.float32)\n",
    "Yset_tensor = torch.from_numpy(np.array(Yset)).to(torch.float32)\n",
    "    \n",
    "# Training data\n",
    "input_data = Xset_tensor \n",
    "target_data = Yset_tensor \n",
    "\n",
    "# Create the model\n",
    "model = TwoToTenNet(dim_x, dim_y)\n",
    "\n",
    "# Define the loss functioy_n and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "ll = []\n",
    "num_epochs = 10000\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # Forward pass\n",
    "    outputs = model(input_data)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs, target_data)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    ll.append(loss.item())\n",
    "\n",
    "plt.plot(ll)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show\n",
    "\n",
    "# Testing the model\n",
    "test_input = torch.tensor([[0.5, 0.5]])  # Example input\n",
    "with torch.no_grad():\n",
    "    predicted_output = model(test_input)\n",
    "    print(\"Predicted Output:\", predicted_output)\n",
    "    \n",
    "PretrainModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e6a65",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T12:10:55.212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pretrain base model of Pareto\n",
    "df_Pset = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(x_n)):\n",
    "    with torch.no_grad():\n",
    "        predicted_output = PretrainModel(torch.tensor([[i/x_n, 1-i/x_n]])).numpy()\n",
    "        df_Pset = pd.concat([df_Pset, pd.DataFrame(predicted_output)], ignore_index=True)\n",
    "\n",
    "df_Pset.columns = df_parameter.columns\n",
    "df_Pset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eae48b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T12:10:55.214Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reward Model\n",
    "class RewardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RewardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 64)  # Input layer: 10 features, Output layer: 64 neurons\n",
    "        self.fc2 = nn.Linear(64, 1)  # Hidden layer: 64 neurons, Output layer: 1 neurons\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # ReLU activation for the first layer\n",
    "        x = self.fc2(x)  # Output layer without activation function\n",
    "        return x\n",
    "\n",
    "    \n",
    "RewardModels = []\n",
    "for i in tqdm(range(x_n)):\n",
    "    flag = True\n",
    "    \n",
    "    parameter_tensor = torch.from_numpy(parameter_mat).to(torch.float32)\n",
    "    Rset_tensor = torch.from_numpy(Rset[i]).to(torch.float32)\n",
    "    \n",
    "    while(flag):\n",
    "        # Training data\n",
    "        input_data = parameter_tensor  # 2500 samples, 10 input features\n",
    "        target_data = Rset_tensor  # 2500 samples, 1 target features\n",
    "\n",
    "        # Create the model\n",
    "        model = RewardNet()\n",
    "\n",
    "        # Define the loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "        # Training loop\n",
    "        ll = []\n",
    "        num_epochs = 1000\n",
    "        for epoch in range(num_epochs):\n",
    "            # Forward pass\n",
    "            outputs = model(input_data)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, target_data)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            ll.append(loss.item())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predicted_output = model(torch.tensor(Pset[i]))\n",
    "            flag = torch.isnan(predicted_output)\n",
    "    \n",
    "    plt.plot(ll)\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show\n",
    "\n",
    "    RewardModels.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67677f81",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T12:10:55.216Z"
    }
   },
   "outputs": [],
   "source": [
    "# RLHF by PG\n",
    "\n",
    "# Policy Gradient Agent\n",
    "class PolicyGradientAgent:\n",
    "    def __init__(self, model, input_data, lr=0.01):\n",
    "        self.policy_net = model\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=lr)\n",
    "        self.input_data = input_data\n",
    "\n",
    "    def select_action(self, state):\n",
    "        return self.policy_net(state)\n",
    "\n",
    "    def update_policy(self, diff):\n",
    "        # Define the loss functioy_n and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "        outputs = self.policy_net(self.input_data)\n",
    "        target_data = #BASE ON REWARDS ASCEND\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, target_data)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "# Example usage\n",
    "agent = PolicyGradientAgent(PretrainModel, Xset_tensor)\n",
    "\n",
    "# Training loop\n",
    "total_rewards = []\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "rewards_old = torch.zeros(x_n)\n",
    "\n",
    "for i in tqdm(range(num_epochs)):\n",
    "    for j in range(x_n):\n",
    "        state = Xset_tensor[j]\n",
    "        action = agent.select_action(state)\n",
    "        rewards_new[j] = RewardModels[j](action)\n",
    "\n",
    "#     diff = rewards_new - rewards_old\n",
    "#     agent.update_policy(diff)\n",
    "#     rewards_old = rewards_new\n",
    "\n",
    "\n",
    "### NEED REDESIGN ACTION SPACE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
