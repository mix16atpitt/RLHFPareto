{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a6853c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:27:01.718375Z",
     "start_time": "2024-02-15T12:26:58.161455Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np, numpy.random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b49062e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:27:01.731112Z",
     "start_time": "2024-02-15T12:27:01.721936Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(random_seed):\n",
    "#     random.seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.benckmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "    \n",
    "set_seed(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb598935",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:27:02.253787Z",
     "start_time": "2024-02-15T12:27:01.731112Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check CUDA\n",
    " \n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    " \n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
    "       \n",
    "print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75db29c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:27:02.295019Z",
     "start_time": "2024-02-15T12:27:02.258469Z"
    }
   },
   "outputs": [],
   "source": [
    "csvFile = pd.read_csv('Dataset/structure4.csv')\n",
    "df_parameter = csvFile.iloc[:, :10]\n",
    "\n",
    "df_SE = csvFile.iloc[:, 10:11]\n",
    "df_Tvis = csvFile.iloc[:, 12:13] * 100\n",
    "df_metric = pd.concat([df_Tvis, df_SE], axis=1)\n",
    "\n",
    "df_parameter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2524c7b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:27:02.306939Z",
     "start_time": "2024-02-15T12:27:02.298015Z"
    }
   },
   "outputs": [],
   "source": [
    "max_values_parameter = df_parameter.max()\n",
    "max_values_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e329f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:27:02.332263Z",
     "start_time": "2024-02-15T12:27:02.309933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalization Parameters\n",
    "df_parameter_norm = df_parameter / max_values_parameter\n",
    "df_parameter_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6673ecdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:27:02.345977Z",
     "start_time": "2024-02-15T12:27:02.335927Z"
    }
   },
   "outputs": [],
   "source": [
    "max_values_metric = df_metric.max()\n",
    "max_values_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbdc1db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:27:02.357661Z",
     "start_time": "2024-02-15T12:27:02.345977Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalization Metrics (Tested: No Difference)\n",
    "\n",
    "SE_max = 120\n",
    "Tvis_max = 100\n",
    "\n",
    "df_SE_norm = df_SE / SE_max\n",
    "df_Tvis_norm = df_Tvis / Tvis_max\n",
    "df_metric_norm = pd.concat([df_Tvis_norm, df_SE_norm], axis=1)\n",
    "\n",
    "plt.scatter(df_Tvis_norm, df_SE_norm, s=0.1)\n",
    "plt.xlabel(\"Tvis(%)_norm\")\n",
    "plt.ylabel(\"SE_norm\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d0d7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:27:02.536828Z",
     "start_time": "2024-02-15T12:27:02.357661Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_Tvis, df_SE, s=0.1)\n",
    "plt.xlabel(\"Tvis(%)\")\n",
    "plt.ylabel(\"SE\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93b3392",
   "metadata": {},
   "source": [
    "Dataset for Reward Model, $\\forall x$: function $r_\\theta : \\mathcal{Y} \\mapsto z$\n",
    "\n",
    "$x$: 2d vector sum to 1\n",
    "\n",
    "$y_i, y_j$: indicate by index\n",
    "\n",
    "$z_{y_i, y_j | x}$: preference output\n",
    "\n",
    "Data for Pretrained Base Pareto Model: function $f_\\theta : \\mathcal{X} \\mapsto \\mathcal{Y}$\n",
    "\n",
    "this can be trained naively: choose the best completion $y_i$ under the most weighted metric(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb8796",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:27:02.672305Z",
     "start_time": "2024-02-15T12:27:02.537571Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Dataset for Reward Model and Pretrained Base Pareto Model\n",
    "parameter_mat = df_parameter.to_numpy()\n",
    "metric_mat = df_metric.to_numpy()\n",
    "\n",
    "dim_x = 2\n",
    "dim_y = len(df_parameter_norm.columns)\n",
    "x_n = 100\n",
    "y_n = len(df_parameter_norm)\n",
    "\n",
    "Xset = []\n",
    "Yset = []\n",
    "Zset = []\n",
    "Mset = []\n",
    "Rset = []\n",
    "\n",
    "for i in tqdm(range(x_n)):\n",
    "    x = np.array(([i/x_n, 1-i/x_n]))\n",
    "    Xset.append(x.flatten())\n",
    "    value_x = np.dot(metric_mat, x.T)\n",
    "\n",
    "    index_sorted = sorted(range(len(value_x)), key=lambda k: value_x[k])\n",
    "    Yset.append(parameter_mat[index_sorted[-1]])\n",
    "    Mset.append(metric_mat[index_sorted[-1]])\n",
    "\n",
    "    \n",
    "    # Reward Dataset Design\n",
    "    Rset.append(np.array([value_x]).T)\n",
    "        \n",
    "#     z_mat = [[0 for i in range(y_n)] for j in range(y_n)]\n",
    "    \n",
    "#     for j in range(y_n):\n",
    "#         z_mat[index_sorted[j]][index_sorted[j]] = np.random.binomial(1, 0.5, 1)\n",
    "#         for k in range(1, y_n - j):\n",
    "#             z_mat[index_sorted[j]][index_sorted[k]] = 1\n",
    "#             z_mat[index_sorted[k]][index_sorted[j]] = 0\n",
    "            \n",
    "#     Zset.append(z_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a723e97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:27:02.818022Z",
     "start_time": "2024-02-15T12:27:02.673628Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pareto from Data for Pretrain base model\n",
    "\n",
    "plt.scatter([Mset[i][0] for i in range(x_n)], [Mset[i][1] for i in range(x_n)], s=0.1)\n",
    "plt.xlabel(\"Tvis(%)\")\n",
    "plt.ylabel(\"SE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1331ab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:27:12.237761Z",
     "start_time": "2024-02-15T12:27:02.820911Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pretrain base model of Pareto\n",
    "class TwoToTenNet(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_size=64):\n",
    "        super(TwoToTenNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, action_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        state = torch.relu(self.fc1(state))  # ReLU activation for the first layer\n",
    "        state = self.fc2(state)  # Output layer without activation function\n",
    "        return state\n",
    "\n",
    "Xset_tensor = torch.from_numpy(np.array(Xset)).to(torch.float32)\n",
    "Yset_tensor = torch.from_numpy(np.array(Yset)).to(torch.float32)\n",
    "    \n",
    "# Training data\n",
    "input_data = Xset_tensor \n",
    "target_data = Yset_tensor \n",
    "\n",
    "# Create the model\n",
    "model = TwoToTenNet(dim_x, dim_y)\n",
    "\n",
    "# Define the loss functioy_n and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "ll = []\n",
    "num_epochs = 10000\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # Forward pass\n",
    "    outputs = model(input_data)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs, target_data)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    ll.append(loss.item())\n",
    "\n",
    "plt.plot(ll)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show\n",
    "\n",
    "# Testing the model\n",
    "test_input = torch.tensor([[0.5, 0.5]])  # Example input\n",
    "with torch.no_grad():\n",
    "    predicted_output = model(test_input)\n",
    "    print(\"Predicted Output:\", predicted_output)\n",
    "    \n",
    "PretrainModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e6a65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:27:12.311178Z",
     "start_time": "2024-02-15T12:27:12.238825Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pretrain base model of Pareto\n",
    "Pset = []\n",
    "df_Pset = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(x_n)):\n",
    "    with torch.no_grad():\n",
    "        predicted_output = PretrainModel(torch.tensor([[i/x_n, 1-i/x_n]])).numpy()\n",
    "        Pset.append(predicted_output)\n",
    "        df_Pset = pd.concat([df_Pset, pd.DataFrame(predicted_output)], ignore_index=True)\n",
    "\n",
    "df_Pset.columns = df_parameter.columns\n",
    "df_Pset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eae48b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:29:39.769952Z",
     "start_time": "2024-02-15T12:27:12.311178Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reward Model\n",
    "class RewardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RewardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 64)  # Input layer: 10 features, Output layer: 64 neurons\n",
    "        self.fc2 = nn.Linear(64, 1)  # Hidden layer: 64 neurons, Output layer: 1 neurons\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # ReLU activation for the first layer\n",
    "        x = self.fc2(x)  # Output layer without activation function\n",
    "        return x\n",
    "\n",
    "    \n",
    "RewardModels = []\n",
    "for i in tqdm(range(x_n)):\n",
    "    flag = True\n",
    "    \n",
    "    parameter_tensor = torch.from_numpy(parameter_mat).to(torch.float32)\n",
    "    Rset_tensor = torch.from_numpy(Rset[i]).to(torch.float32)\n",
    "    \n",
    "    while(flag):\n",
    "        # Training data\n",
    "        input_data = parameter_tensor  # 2500 samples, 10 input features\n",
    "        target_data = Rset_tensor  # 2500 samples, 1 target features\n",
    "\n",
    "        # Create the model\n",
    "        model = RewardNet()\n",
    "\n",
    "        # Define the loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "        # Training loop\n",
    "        ll = []\n",
    "        num_epochs = 1000\n",
    "        for epoch in range(num_epochs):\n",
    "            # Forward pass\n",
    "            outputs = model(input_data)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, target_data)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            ll.append(loss.item())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predicted_output = model(torch.tensor(Pset[i]))\n",
    "            flag = torch.isnan(predicted_output)\n",
    "    \n",
    "    plt.plot(ll)\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show\n",
    "\n",
    "    RewardModels.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67677f81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T12:29:39.782648Z",
     "start_time": "2024-02-15T12:29:39.772707Z"
    }
   },
   "outputs": [],
   "source": [
    "# RLHF by PG\n",
    "\n",
    "# Policy Gradient Agent\n",
    "class PolicyGradientAgent:\n",
    "    def __init__(self, model, input_data, lr=0.01):\n",
    "        self.policy_net = model\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=lr)\n",
    "        self.input_data = input_data\n",
    "\n",
    "    def select_action(self, state):\n",
    "        return self.policy_net(state)\n",
    "\n",
    "    def update_policy(self, diff):\n",
    "        # Define the loss functioy_n and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "# Example usage\n",
    "agent = PolicyGradientAgent(PretrainModel, Xset_tensor)\n",
    "\n",
    "# Training loop\n",
    "total_rewards = []\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "rewards_old = torch.zeros(x_n)\n",
    "\n",
    "for i in tqdm(range(num_epochs)):\n",
    "    for j in range(x_n):\n",
    "        state = Xset_tensor[j]\n",
    "        action = agent.select_action(state)\n",
    "        rewards_new[j] = RewardModels[j](action)\n",
    "\n",
    "#     diff = rewards_new - rewards_old\n",
    "#     agent.update_policy(diff)\n",
    "#     rewards_old = rewards_new\n",
    "\n",
    "\n",
    "### NEED REDESIGN ACTION SPACE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
